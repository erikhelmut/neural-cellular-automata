{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAModel(nn.Module):\n",
    "    \"\"\"Cell automata model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_channels : int\n",
    "        Number of channels of the grid.\n",
    "\n",
    "    hidden_channels : int\n",
    "        Hidden channels that are related to the pixelwise 1x1 convolution.\n",
    "\n",
    "    fire_rate : float\n",
    "        Number between 0 and 1. The lower it is the more likely it is for\n",
    "        cells to be set to zero during the `stochastic_update` process.\n",
    "\n",
    "    device : torch.device\n",
    "        Determines on what device we perfrom all the computations.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    update_module : nn.Sequential\n",
    "        The only part of the network containing trainable parameters. Composed\n",
    "        of 1x1 convolution, ReLu and 1x1 convolution.\n",
    "\n",
    "    filters : torch.Tensor\n",
    "        Constant tensor of shape `(3 * n_channels, 1, 3, 3)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=16, hidden_channels=128, fire_rate=0.5, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fire_rate = 0.5\n",
    "        self.n_channels = n_channels\n",
    "        self.device = device or torch.device(\"cpu\")\n",
    "\n",
    "        # Perceive step\n",
    "        sobel_filter_ = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        scalar = 8.0\n",
    "\n",
    "        sobel_filter_x = sobel_filter_ / scalar\n",
    "        sobel_filter_y = sobel_filter_.t() / scalar\n",
    "        identity_filter = torch.tensor(\n",
    "                [\n",
    "                    [0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0],\n",
    "                ],\n",
    "                dtype=torch.float32,\n",
    "        )\n",
    "        filters = torch.stack(\n",
    "                [identity_filter, sobel_filter_x, sobel_filter_y]\n",
    "        )  # (3, 3, 3)\n",
    "        filters = filters.repeat((n_channels, 1, 1))  # (3 * n_channels, 3, 3)\n",
    "        self.filters = filters[:, None, ...].to(\n",
    "                self.device\n",
    "        )  # (3 * n_channels, 1, 3, 3)\n",
    "\n",
    "        # Update step\n",
    "        self.update_module = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    3 * n_channels,\n",
    "                    hidden_channels,\n",
    "                    kernel_size=1,  # (1, 1)\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(\n",
    "                    hidden_channels,\n",
    "                    n_channels,\n",
    "                    kernel_size=1,\n",
    "                    bias=False,\n",
    "                ),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.update_module[2].weight.zero_()\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def perceive(self, x):\n",
    "        \"\"\"Approximate channelwise gradient and combine with the input.\n",
    "\n",
    "        This is the only place where we include information on the\n",
    "        neighboring cells. However, we are not using any learnable\n",
    "        parameters here.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        return nn.functional.conv2d(x, self.filters, padding=1, groups=self.n_channels)\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Perform update.\n",
    "\n",
    "        Note that this is the only part of the forward pass that uses\n",
    "        trainable parameters\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        return self.update_module(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def stochastic_update(x, fire_rate):\n",
    "        \"\"\"Run pixel-wise dropout.\n",
    "\n",
    "        Unlike dropout there is no scaling taking place.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        fire_rate : float\n",
    "            Number between 0 and 1. The higher the more likely a given cell\n",
    "            updates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        mask = (torch.rand(x[:, :1, :, :].shape) <= fire_rate).to(device, torch.float32)\n",
    "        return x * mask  # broadcasted over all channels\n",
    "\n",
    "    @staticmethod\n",
    "    def get_living_mask(x):\n",
    "        \"\"\"Identify living cells.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, 1, grid_size, grid_size)` and the\n",
    "            dtype is bool.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            nn.functional.max_pool2d(\n",
    "                x[:, 3:4, :, :], kernel_size=3, stride=1, padding=1\n",
    "            )\n",
    "            > 0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run the forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_sample, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        pre_life_mask = self.get_living_mask(x)\n",
    "\n",
    "        y = self.perceive(x)\n",
    "        dx = self.update(y)\n",
    "        dx = self.stochastic_update(dx, fire_rate=self.fire_rate)\n",
    "\n",
    "        x = x + dx\n",
    "\n",
    "        post_life_mask = self.get_living_mask(x)\n",
    "        life_mask = (pre_life_mask & post_life_mask).to(torch.float32)\n",
    "\n",
    "        return x * life_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=40):\n",
    "    \"\"\"Load an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : pathlib.Path\n",
    "        Path to where the image is located. Note that the image needs to be\n",
    "        RGBA.\n",
    "\n",
    "    size : int\n",
    "        The image will be resized to a square wit ha side length of `size`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        4D float image of shape `(1, 4, size, size)`. The RGB channels\n",
    "        are premultiplied by the alpha channel.\n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((size, size), Image.ANTIALIAS)\n",
    "    img = np.float32(img) / 255.0\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(img_rgba):\n",
    "    \"\"\"Convert RGBA image to RGB image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_rgba : torch.Tensor\n",
    "        4D tensor of shape `(1, 4, size, size)` where the RGB channels\n",
    "        were already multiplied by the alpha.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img_rgb : torch.Tensor\n",
    "        4D tensor of shape `(1, 3, size, size)`.\n",
    "    \"\"\"\n",
    "    rgb, a = img_rgba[:, :3, ...], torch.clamp(img_rgba[:, 3:, ...], 0, 1)\n",
    "    return torch.clamp(1.0 - a + rgb, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seed(size, n_channels):\n",
    "    \"\"\"Create a starting tensor for training.\n",
    "\n",
    "    The only active pixels are going to be in the middle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        The height and the width of the tensor.\n",
    "\n",
    "    n_channels : int\n",
    "        Overall number of channels. Note that it needs to be higher than 4\n",
    "        since the first 4 channels represent RGBA.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        4D float tensor of shape `(1, n_chanels, size, size)`.\n",
    "    \"\"\"\n",
    "    x = torch.zeros((1, n_channels, size, size), dtype=torch.float32)\n",
    "    x[:, 3:, size // 2, size // 2] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "            description=\"Training script for the Celluar Automata\"\n",
    "    )\n",
    "    parser.add_argument(\"-j\",\n",
    "                        \"--img\", \n",
    "                        type=str, \n",
    "                        default=\"rabbit.png\", \n",
    "                        help=\"Path to the image we want to reproduce\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "            \"-b\",\n",
    "            \"--batch-size\",\n",
    "            type=int,\n",
    "            default=8,\n",
    "            help=\"Batch size. Samples will always be taken randomly from the pool.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-d\",\n",
    "            \"--device\",\n",
    "            type=str,\n",
    "            default=\"cpu\",\n",
    "            help=\"Device to use\",\n",
    "            choices=(\"cpu\", \"cuda\"),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-e\",\n",
    "            \"--eval-frequency\",\n",
    "            type=int,\n",
    "            default=500,\n",
    "            help=\"Evaluation frequency.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-i\",\n",
    "            \"--eval-iterations\",\n",
    "            type=int,\n",
    "            default=300,\n",
    "            help=\"Number of iterations when evaluating.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-n\",\n",
    "            \"--n-batches\",\n",
    "            type=int,\n",
    "            default=5000,\n",
    "            help=\"Number of batches to train for.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-c\",\n",
    "            \"--n-channels\",\n",
    "            type=int,\n",
    "            default=16,\n",
    "            help=\"Number of channels of the input tensor\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-l\",\n",
    "            \"--logdir\",\n",
    "            type=str,\n",
    "            default=\"logs\",\n",
    "            help=\"Folder where all the logs and outputs are saved.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-p\",\n",
    "            \"--padding\",\n",
    "            type=int,\n",
    "            default=16,\n",
    "            help=\"Padding. The shape after padding is (h + 2 * p, w + 2 * p).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"--pool-size\",\n",
    "            type=int,\n",
    "            default=1024,\n",
    "            help=\"Size of the training pool\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"-s\",\n",
    "            \"--size\",\n",
    "            type=int,\n",
    "            default=40,\n",
    "            help=\"Image size\",\n",
    "    )\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "    print(vars(args))\n",
    "\n",
    "    # Misc\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    log_path = pathlib.Path(args.logdir)\n",
    "    log_path.mkdir(parents=True, exist_ok=True)\n",
    "    writer = SummaryWriter(log_path)\n",
    "\n",
    "    # Target image\n",
    "    target_img_ = load_image(args.img, size=args.size)\n",
    "    p = args.padding\n",
    "    target_img_ = nn.functional.pad(target_img_, (p, p, p, p), \"constant\", 0)\n",
    "    target_img = target_img_.to(device)\n",
    "    target_img = target_img.repeat(args.batch_size, 1, 1, 1)\n",
    "\n",
    "    writer.add_image(\"ground truth\", to_rgb(target_img_)[0])\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = CAModel(n_channels=args.n_channels, device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "    # Pool initialization\n",
    "    seed = make_seed(args.size, args.n_channels).to(device)\n",
    "    seed = nn.functional.pad(seed, (p, p, p, p), \"constant\", 0)\n",
    "    pool = seed.clone().repeat(args.pool_size, 1, 1, 1)\n",
    "\n",
    "    for it in tqdm(range(args.n_batches)):\n",
    "        batch_ixs = np.random.choice(\n",
    "                args.pool_size, args.batch_size, replace=False\n",
    "        ).tolist()\n",
    "\n",
    "        x = pool[batch_ixs]\n",
    "        for i in range(np.random.randint(64, 96)):\n",
    "            x = model(x)\n",
    "\n",
    "        loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "        loss = loss_batch.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"train/loss\", loss, it)\n",
    "\n",
    "        argmax_batch = loss_batch.argmax().item()\n",
    "        argmax_pool = batch_ixs[argmax_batch]\n",
    "        remaining_batch = [i for i in range(args.batch_size) if i != argmax_batch]\n",
    "        remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "\n",
    "        pool[argmax_pool] = seed.clone()\n",
    "        pool[remaining_pool] = x[remaining_batch].detach()\n",
    "\n",
    "        if it % args.eval_frequency == 0:\n",
    "            x_eval = seed.clone()  # (1, n_channels, size, size)\n",
    "\n",
    "            eval_video = torch.empty(1, args.eval_iterations, 3, *x_eval.shape[2:])\n",
    "\n",
    "            for it_eval in range(args.eval_iterations):\n",
    "                x_eval = model(x_eval)\n",
    "                x_eval_out = to_rgb(x_eval[:, :4].detach().cpu())\n",
    "                eval_video[0, it_eval] = x_eval_out\n",
    "\n",
    "            writer.add_video(\"eval\", eval_video, it, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
