{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/jankrepl/mildlyoverfitted/tree/master/github_adventures/automata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAModel(nn.Module):\n",
    "    \"\"\"Cell automata model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_channels : int\n",
    "        Number of channels of the grid.\n",
    "\n",
    "    hidden_channels : int\n",
    "        Hidden channels that are related to the pixelwise 1x1 convolution.\n",
    "\n",
    "    fire_rate : float\n",
    "        Number between 0 and 1. The lower it is the more likely it is for\n",
    "        cells to be set to zero during the `stochastic_update` process.\n",
    "\n",
    "    device : torch.device\n",
    "        Determines on what device we perfrom all the computations.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    update_module : nn.Sequential\n",
    "        The only part of the network containing trainable parameters. Composed\n",
    "        of 1x1 convolution, ReLu and 1x1 convolution.\n",
    "\n",
    "    filters : torch.Tensor\n",
    "        Constant tensor of shape `(3 * n_channels, 1, 3, 3)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=16, hidden_channels=128, fire_rate=0.5, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.fire_rate = 0.5\n",
    "        self.n_channels = n_channels\n",
    "        self.device = device or torch.device(\"cpu\")\n",
    "\n",
    "        # Perceive step\n",
    "        sobel_filter_ = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        scalar = 8.0\n",
    "\n",
    "        sobel_filter_x = sobel_filter_ / scalar\n",
    "        sobel_filter_y = sobel_filter_.t() / scalar\n",
    "        identity_filter = torch.tensor(\n",
    "                [\n",
    "                    [0, 0, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 0, 0],\n",
    "                ],\n",
    "                dtype=torch.float32,\n",
    "        )\n",
    "        filters = torch.stack(\n",
    "                [identity_filter, sobel_filter_x, sobel_filter_y]\n",
    "        )  # (3, 3, 3)\n",
    "        filters = filters.repeat((n_channels, 1, 1))  # (3 * n_channels, 3, 3)\n",
    "        self.filters = filters[:, None, ...].to(\n",
    "                self.device\n",
    "        )  # (3 * n_channels, 1, 3, 3)\n",
    "\n",
    "        # Update step\n",
    "        self.update_module = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    3 * n_channels,\n",
    "                    hidden_channels,\n",
    "                    kernel_size=1,  # (1, 1)\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(\n",
    "                    hidden_channels,\n",
    "                    n_channels,\n",
    "                    kernel_size=1,\n",
    "                    bias=False,\n",
    "                ),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.update_module[2].weight.zero_()\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def perceive(self, x):\n",
    "        \"\"\"Approximate channelwise gradient and combine with the input.\n",
    "\n",
    "        This is the only place where we include information on the\n",
    "        neighboring cells. However, we are not using any learnable\n",
    "        parameters here.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        return nn.functional.conv2d(x, self.filters, padding=1, groups=self.n_channels)\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Perform update.\n",
    "\n",
    "        Note that this is the only part of the forward pass that uses\n",
    "        trainable parameters\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        return self.update_module(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def stochastic_update(x, fire_rate):\n",
    "        \"\"\"Run pixel-wise dropout.\n",
    "\n",
    "        Unlike dropout there is no scaling taking place.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        fire_rate : float\n",
    "            Number between 0 and 1. The higher the more likely a given cell\n",
    "            updates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        mask = (torch.rand(x[:, :1, :, :].shape) <= fire_rate).to(device, torch.float32)\n",
    "        return x * mask  # broadcasted over all channels\n",
    "\n",
    "    @staticmethod\n",
    "    def get_living_mask(x):\n",
    "        \"\"\"Identify living cells.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_samples, 1, grid_size, grid_size)` and the\n",
    "            dtype is bool.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            nn.functional.max_pool2d(\n",
    "                x[:, 3:4, :, :], kernel_size=3, stride=1, padding=1\n",
    "            )\n",
    "            > 0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run the forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape `(n_sample, n_channels, grid_size, grid_size)`.\n",
    "        \"\"\"\n",
    "        pre_life_mask = self.get_living_mask(x)\n",
    "\n",
    "        y = self.perceive(x)\n",
    "        dx = self.update(y)\n",
    "        dx = self.stochastic_update(dx, fire_rate=self.fire_rate)\n",
    "\n",
    "        x = x + dx\n",
    "\n",
    "        post_life_mask = self.get_living_mask(x)\n",
    "        life_mask = (pre_life_mask & post_life_mask).to(torch.float32)\n",
    "\n",
    "        return x * life_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=40):\n",
    "    \"\"\"Load an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : pathlib.Path\n",
    "        Path to where the image is located. Note that the image needs to be\n",
    "        RGBA.\n",
    "\n",
    "    size : int\n",
    "        The image will be resized to a square wit ha side length of `size`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        4D float image of shape `(1, 4, size, size)`. The RGB channels\n",
    "        are premultiplied by the alpha channel.\n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((size, size), Image.ANTIALIAS)\n",
    "    img = np.float32(img) / 255.0\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "\n",
    "    return torch.from_numpy(img).permute(2, 0, 1)[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(img_rgba):\n",
    "    \"\"\"Convert RGBA image to RGB image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_rgba : torch.Tensor\n",
    "        4D tensor of shape `(1, 4, size, size)` where the RGB channels\n",
    "        were already multiplied by the alpha.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img_rgb : torch.Tensor\n",
    "        4D tensor of shape `(1, 3, size, size)`.\n",
    "    \"\"\"\n",
    "    rgb, a = img_rgba[:, :3, ...], torch.clamp(img_rgba[:, 3:, ...], 0, 1)\n",
    "    return torch.clamp(1.0 - a + rgb, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seed(size, n_channels):\n",
    "    \"\"\"Create a starting tensor for training.\n",
    "\n",
    "    The only active pixels are going to be in the middle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        The height and the width of the tensor.\n",
    "\n",
    "    n_channels : int\n",
    "        Overall number of channels. Note that it needs to be higher than 4\n",
    "        since the first 4 channels represent RGBA.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        4D float tensor of shape `(1, n_chanels, size, size)`.\n",
    "    \"\"\"\n",
    "    x = torch.zeros((1, n_channels, size, size), dtype=torch.float32)\n",
    "    x[:, 3:, size // 2, size // 2] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/vydzn9mx7vg652lct5mbtrqh0000gn/T/ipykernel_90911/861228583.py:20: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((size, size), Image.ANTIALIAS)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f437e32e12445eb841cdc3042a3635c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = \"../data/rabbit.png\"\n",
    "batch_size = 8\n",
    "device = \"mps\"\n",
    "eval_frequency = 500\n",
    "eval_iterations = 300\n",
    "n_batches = 1000 #5000\n",
    "n_channels = 16\n",
    "logdir = \"logs\"\n",
    "padding = 16\n",
    "pool_size = 1024\n",
    "size = 40\n",
    "\n",
    "# Misc\n",
    "device = torch.device(device)\n",
    "\n",
    "log_path = pathlib.Path(logdir)\n",
    "log_path.mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "# Target image\n",
    "target_img_ = load_image(img, size=size)\n",
    "p = padding\n",
    "target_img_ = nn.functional.pad(target_img_, (p, p, p, p), \"constant\", 0)\n",
    "target_img = target_img_.to(device)\n",
    "target_img = target_img.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "writer.add_image(\"ground truth\", to_rgb(target_img_)[0])\n",
    "\n",
    "# Model and optimizer\n",
    "model = CAModel(n_channels=n_channels, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "# Pool initialization\n",
    "seed = make_seed(size, n_channels).to(device)\n",
    "seed = nn.functional.pad(seed, (p, p, p, p), \"constant\", 0)\n",
    "pool = seed.clone().repeat(pool_size, 1, 1, 1)\n",
    "\n",
    "for it in tqdm(range(n_batches)):\n",
    "    batch_ixs = np.random.choice(\n",
    "            pool_size, batch_size, replace=False\n",
    "    ).tolist()\n",
    "\n",
    "    x = pool[batch_ixs]\n",
    "    for i in range(np.random.randint(64, 96)):\n",
    "        x = model(x)\n",
    "\n",
    "    loss_batch = ((target_img - x[:, :4, ...]) ** 2).mean(dim=[1, 2, 3])\n",
    "    loss = loss_batch.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar(\"train/loss\", loss, it)\n",
    "\n",
    "    argmax_batch = loss_batch.argmax().item()\n",
    "    argmax_pool = batch_ixs[argmax_batch]\n",
    "    remaining_batch = [i for i in range(batch_size) if i != argmax_batch]\n",
    "    remaining_pool = [i for i in batch_ixs if i != argmax_pool]\n",
    "\n",
    "    pool[argmax_pool] = seed.clone()\n",
    "    pool[remaining_pool] = x[remaining_batch].detach()\n",
    "\n",
    "    if it % eval_frequency == 0:\n",
    "        x_eval = seed.clone()  # (1, n_channels, size, size)\n",
    "\n",
    "        eval_video = torch.empty(1, eval_iterations, 3, *x_eval.shape[2:])\n",
    "\n",
    "        for it_eval in range(eval_iterations):\n",
    "            x_eval = model(x_eval)\n",
    "            x_eval_out = to_rgb(x_eval[:, :4].detach().cpu())\n",
    "            eval_video[0, it_eval] = x_eval_out\n",
    "\n",
    "        writer.add_video(\"eval\", eval_video, it, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
